---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---
# 2024
* FedComLoc: Communication-Efficient Distributed Training of Sparse and Quantized Models            
  **Kai Yi**, Georg Meinhardt, Laurent Condat, Peter Richtárik             
  arXiv, 2024. [[arXiv]](https://arxiv.org/abs/2403.09904) [[code (coming soon)]](https://github.com/WilliamYi96/FedComLoc)
  
* FedP3: Federated Personalized and Privacy-friendly  Network Pruning under Model Heterogeneity          
  **Kai Yi**, Nidham Gazagnadou, Peter Richtárik, Lingjuan Lyu                    
  ICLR, 2024. [[paper]](https://openreview.net/forum?id=hbHwZYqk9T)  [[code (coming soon)]]()
  

# 2023
* Domain-Aware Continual Zero-Shot Learning          
  **Kai Yi**, Mohamed Elhoseiny           
  ICCV Workshop [OOD-CV](https://www.ood-cv.org/), 2023. [[paper]](https://arxiv.org/abs/2112.12989) [[project]](https://kaiyi.me/p/daczsl)
  
* Continual Zero-Shot Learning through Semantically Guided Generative Random Walks                      
  Wenxuan Zhang, Paul Janson, **Kai Yi**, Ivan Skorokhodov, Mohamed Elhoseiny  
  ICCV, 2023. [[paper]](https://arxiv.org/abs/2308.12366) [[code]](https://github.com/wx-zhang/IGCZSL)

* Explicit Personalization and Local Training: Double Communication Acceleration in Federated Learning       
  **Kai Yi**, Laurent Condat, Peter Richtárik        
  arXiv, 2023. [[paper]](https://arxiv.org/abs/2305.13170) [[code]](https://github.com/WilliamYi96/Scafflix)

# 2022
* Variance Reduced ProxSkip: Algorithm, Theory and Application to Federated Learning                    
  Grigory Malinovsky, **Kai Yi**, Peter Richtárik                
  NeurIPS, 2022. [[paper]](https://arxiv.org/abs/2207.04338) [[code]](https://github.com/WilliamYi96/VR-ProxSkip)
  
* Exploring Hierarchical Graph Representation for Large-Scale Zero-Shot Image Classification            
  **Kai Yi**, Xiaoqian Shen, Yunhao Gou, Mohamed Elhoseiny               
  ECCV, 2022. [[paper]](https://arxiv.org/abs/2203.01386) [[project]](https://kaiyi.me/p/hgrnet) [[code]](https://github.com/WilliamYi96/HGR-Net)
  
* EF-BV: A Unified Theory of Error Feedback and Variance Reduction Mechanisms for Biased and Unbiased Compression in Distributed Optimization             
  Laurent Condat, **Kai Yi**, Peter Richtárik                          
  NeurIPS, 2022. [[paper]](https://arxiv.org/abs/2205.04180) [[code]](https://github.com/WilliamYi96/EF-BV)

* Language-Guided Imaginative Walks: Generative Random Walk Deviation Loss for Unseen Class Recognition using Text         
  **Kai Yi**, Divyansh Jha, Ivan Skorokhodov, Mohamed Elhoseiny              
  CVPR, 2022, L3D-IVU Workshop (Short Paper). [[paper]](https://arxiv.org/abs/2104.09757) [[code]](https://github.com/Vision-CAIR/GRaWD)
  
* Creative Walk Adversarial Networks: Novel Art Generation with Probabilistic Random Walk Deviation from Style Norms         
  Divyansh Jha\*, **Kai Yi**, Ivan Skorokhodov, Mohamed Elhoseiny\*            
  ICCC, 2022. [[project]](https://kaiyi.me/p/grawd) [[paper]](https://computationalcreativity.net/iccc22/wp-content/uploads/2022/06/ICCC-2022_11L_Jha-et-al..pdf) [[code]](https://github.com/Vision-CAIR/GRaWD)
  
* VisualGPT: Data-efficient Image Captioning by Balancing Visual Input and Linguistic Knowledge from Pretraining             
  Jun Chen, Han Guo, **Kai Yi**, Boyang Li, Mohamed Elhoseiny              
  CVPR, 2022. [[arXiv]](https://arxiv.org/abs/2102.10407) [[CVF]](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_VisualGPT_Data-Efficient_Adaptation_of_Pretrained_Language_Models_for_Image_Captioning_CVPR_2022_paper.pdf) [[code]](https://github.com/Vision-CAIR/VisualGPT)
  
* CIZSL++: Creativity Inspired Generative Zero-Shot Learning            
  Mohamed Elhoseiny, **Kai Yi**,  Mohamed Elfeki               
  T-PAMI Major Revision. [[paper]](https://arxiv.org/abs/2101.00173) [[code]](https://github.com/Elhoseiny-VisionCAIR-Lab/CIZSL.v2).
  
# 2021
* Domain-Aware Continual Zero-Shot Learning       
  **Kai Yi**                       
  Master Thesis, 2021. [[thesis]](https://repository.kaust.edu.sa/handle/10754/673833) 
  
* Imaginative Walks: Generative Random Walk Deviation Loss for Improved Unseen Learning Representation                
  Divyansh Jha\*, **Kai Yi**\*, Ivan Skorokhodov, Mohamed Elhoseiny           
  arXiv, 2021. [[project page]](https://kaiyi.me/p/grawd) [[paper]](https://arxiv.org/abs/2104.09757) [[code]](https://github.com/Vision-CAIR/GRaWD)   
 
* Disentangling semantic features of macromolecules in Cryo-Electron Tomography                                                         
  **Kai Yi**, Jianye Pang, Yungeng Zhang, Xiangrui Zeng, Min Xu                                                             
  arXiv, 2021. [[paper]](https://arxiv.org/abs/2106.14192)

* Unsupervised Domain Alignment based Open Set Structural Recognition of Macromolecules Captured by Cryo-Electron Tomography      
  Yuchen Zeng, Gregory Howe, **Kai Yi**, Xiangrui Zeng, Jing Zhang, Yi-Wei Chang, Min Xu        
  ICIP 2021. [[paper]](https://ieeexplore.ieee.org/document/9506205)

# 2020 and before 
* Experimental Analysis of Legendre Decomposition in Machine Learning                 
  Jianye Pang, **Kai Yi**, Wanguang Yin, [Min Xu](https://xulabs.github.io/#aboutxu)               
  Technical Report, 2020. [[arXiv]](https://arxiv.org/abs/2008.05095)
  
* Feature Selective Small Object Detection via Knowledge-based Recurrent Attentive Neural Network                     
  **Kai Yi**, Zhiqiang Jian, Shitao Chen, [Nanning Zheng](http://www.aiar.xjtu.edu.cn/info/1015/1071.htm)                    
  Technical Report, 2019. [[paper]](https://arxiv.org/abs/1803.05263v4)
  
* Affine LBG for Codebook Training of Univariate Linear Approximation          
  Tiannan Dong, Jianji Wang, Meng Yang, **Yi Kai**, Nanning Zheng          
  GlobalSIP, 2018. [[paper]](https://ieeexplore.ieee.org/abstract/document/8646389/)

* Cognition-Based Deep Learning: Progresses and Perspectives           
  **Kai Yi**, Shitao Chen, Yu Chen, Chao Xia, [Nanning Zheng](http://www.aiar.xjtu.edu.cn/info/1015/1071.htm)          
  AIAI, 2018. [[paper]](https://link.springer.com/chapter/10.1007/978-3-319-92007-8_11)


